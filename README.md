# Evolve Common Service

A common backend service for document processing, AI agents, and more, built with FastAPI. This project serves as the core infrastructure for various AI-powered applications.

---

## âœ¨ Features

- **Document Processing**: Uploading, parsing (`docling`), and chunking.
- **Document Structuring**: Hierarchical parsing of HTML documents based on heading levels.
- **AI Capabilities**: Extensible design for future embedding and reranking services.
- **Agentic Workflows**: Utilizes `langgraph` to build complex, stateful AI agents.
- **Modern API**: Asynchronous API built with FastAPI, with automatic Swagger/OpenAPI documentation.
- **Containerized**: Comes with a Docker and Docker Compose setup for easy development and deployment.
- **Database Migrations**: Uses Alembic for robust database schema versioning.

## ğŸ› ï¸ Tech Stack

- **Backend**: Python 3.11
- **Framework**: FastAPI
- **Database**: PostgreSQL
- **ORM & Migrations**: SQLAlchemy, Alembic
- **AI/LLM Frameworks**: LangGraph, Docling, Langchain
- **Dependency Management**: Poetry
- **Containerization**: Docker, Docker Compose

## ğŸš€ Getting Started with Docker (Recommended)

This is the recommended way to run the project for both development and production.

### 1. Prerequisites

- [Docker](https://docs.docker.com/get-docker/)
- [Docker Compose](https://docs.docker.com/compose/install/)

### 2. Configure Environment Variables

Create a `.env` file in the project root. You can copy the contents below as a template.

```env
# .env

# PostgreSQL Settings for Docker Compose
POSTGRES_USER=user
POSTGRES_PASSWORD=password
POSTGRES_DB=evolve
POSTGRES_HOST=db
POSTGRES_PORT=5432

# DATABASE_URL for Alembic and FastAPI
# This connects the application running in the 'api' service to the 'db' service.
DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}

# Application settings
# Add any other application-specific environment variables here.
```
This file is listed in `.gitignore` and will not be committed to the repository.

### 3. Build and Run the Containers

Use Docker Compose to build the images and start the services.

```bash
# å¯åŠ¨å®¹å™¨
docker compose up --build -d
# åœæ­¢å¹¶ç§»é™¤æ‰€æœ‰å®¹å™¨
docker compose down
# ä»…åœæ­¢å®¹å™¨
docker compose stop
# æ—¥å¿—æŸ¥è¯¢
docker-compose logs api
# è¿›å…¥ API å®¹å™¨çš„ Python äº¤äº’å¼ç¯å¢ƒ
docker-compose exec api python
# æ›´æ–°åé‡å¯æœåŠ¡
docker-compose restart api
```
The `-d` flag runs the containers in detached mode.

The API service will be running and available at `http://127.0.0.1:8000`.

### 4. Run Database Migrations

After starting the containers, apply the database migrations.

```bash
docker compose exec api poetry run alembic upgrade head
```

## ğŸ“„ API Documentation

Once the server is running, the interactive API documentation (Swagger UI) is automatically generated and can be accessed at:

- **Swagger UI**: `http://127.0.0.1:8000/docs`
- **ReDoc**: `http://127.0.0.1:8000/redoc`

## ğŸ—„ï¸ Database Migrations with Docker

When you make changes to the SQLAlchemy models in `api/models/`, you need to generate a new migration script.

- **To create a new migration:**
  ```bash
  <!-- ## To create a new migration -->
  <!-- ### This will generate a new script in the `alembic/versions/` directory. -->
  docker compose exec api poetry run alembic revision --autogenerate -m "Your descriptive message"

  <!-- ## To apply migrations -->
  docker compose exec api poetry run alembic upgrade head

  <!-- ##To downgrade a migration -->
  docker compose exec api poetry run alembic downgrade -1
  ```
```bash
  # è¿›å…¥ PostgreSQL å®¹å™¨çš„äº¤äº’å¼å‘½ä»¤è¡Œ
docker-compose exec db psql -U user -d evolve
```

```sql
-- åˆ—å‡ºæ‰€æœ‰è¡¨
\dt

-- æŸ¥çœ‹ documents è¡¨ç»“æ„
\d documents

-- æŸ¥è¯¢ documents è¡¨ä¸­çš„æ‰€æœ‰è®°å½•
SELECT * FROM documents;

-- é€€å‡º psql
\q
```

## ğŸ‘¨â€ğŸ’» Local Development without Docker

If you prefer not to use Docker, you can run the project locally.

### Install Dependencies & Run

```bash
poetry install
poetry run alembic upgrade head
poetry run uvicorn api.index:app --reload --port 8000
```

## ä¾èµ–ç®¡ç†

æœ¬é¡¹ç›®ä½¿ç”¨ `pyproject.toml` ä½œä¸ºä¸»è¦ä¾èµ–ç®¡ç†æ–‡ä»¶ï¼Œå¹¶ä½¿ç”¨ `uv` ä½œä¸ºåŒ…ç®¡ç†å·¥å…·ã€‚

### 

```bash
# å®‰è£… uv
brew install uv
# è®¾ç½®å¼€å‘ç¯å¢ƒ
make setup
# ç”Ÿæˆ requirements.txt
make requirements
```

è¿™å°†ä» `pyproject.toml` ç”Ÿæˆ `requirements.txt` å’Œ `requirements-minimal.txt` æ–‡ä»¶ï¼Œç”¨äº Docker æ„å»ºå’Œå…¶ä»–éœ€è¦ requirements.txt çš„åœºæ™¯ã€‚

## æœ¬åœ°å¼€å‘

### å¯åŠ¨æ•°æ®åº“ & è¿è¡Œæ•°æ®åº“è¿ç§»

```bash
make docker-db
make migrate
```

## å¯åŠ¨å¼€å‘æœåŠ¡å™¨ & Docker éƒ¨ç½²

### æ„å»ºå’Œè¿è¡Œ Docker å®¹å™¨
```bash
make dev
# é¦–å…ˆç”Ÿæˆ requirements.txt
make requirements
# ç„¶åæ„å»ºå¹¶å¯åŠ¨å®¹å™¨
docker-compose up -d --build
# æ£€æŸ¥dockeræœåŠ¡
docker ps | grep postgres
```

## API æ–‡æ¡£

å¯åŠ¨æœåŠ¡åï¼Œå¯ä»¥è®¿é—®ä»¥ä¸‹ URL æŸ¥çœ‹ API æ–‡æ¡£ï¼š

- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

---

## ğŸ“‚ Project Structure

```
/
â”œâ”€â”€ alembic/              # Database migration scripts
â”œâ”€â”€ api/                  # All application source code
â”‚   â”œâ”€â”€ core/             # Core logic, settings
â”‚   â”œâ”€â”€ db/               # Database session management and base models
â”‚   â”œâ”€â”€ endpoints/        # API route definitions
â”‚   â”œâ”€â”€ models/           # SQLAlchemy data models
â”‚   â”œâ”€â”€ schemas/          # Pydantic data schemas (for API I/O)
â”‚   â”œâ”€â”€ services/         # Business logic services
â”‚   â””â”€â”€ index.py          # FastAPI application entrypoint
â”œâ”€â”€ tests/                # Application tests
â”œâ”€â”€ .gitignore            # Git ignore file
â”œâ”€â”€ alembic.ini           # Alembic configuration
â”œâ”€â”€ Dockerfile            # Dockerfile for the application
â”œâ”€â”€ docker-compose.yml    # Docker Compose configuration
â”œâ”€â”€ pyproject.toml        # Project dependencies and metadata (Poetry)
â””â”€â”€ README.md             # This file
```

## ğŸ“‘ Document Structure Parsing

The system implements a hierarchical document structure parsing capability based on HTML heading levels:

### Key Features

- **Hierarchical Structure**: Documents are parsed according to heading levels (h1-h6), creating a proper tree structure.
- **Intelligent Content Grouping**: Content elements (text, tables, images) are grouped under their parent headings.
- **Merged Text Blocks**: Consecutive text elements under the same heading are merged for cleaner structure.
- **Four Basic Node Types**:
  - `HEADER`: Heading elements (h1-h6), forming the structure backbone
  - `TABLE`: Table elements with metadata about rows and columns
  - `IMAGE`: Image elements with source and alt information
  - `TEXT`: All other textual content including paragraphs, lists, and quotes

### Structure Example

```
h1: Document Title                (depth 0)
â”œâ”€â”€ Text Block                    (depth 1)
â”œâ”€â”€ Table                         (depth 1)
â”œâ”€â”€ h2: First Chapter             (depth 1)
â”‚   â”œâ”€â”€ Text Block                (depth 2)
â”‚   â”œâ”€â”€ Image                     (depth 2)
â”‚   â””â”€â”€ h3: First Section         (depth 2)
â”‚       â””â”€â”€ Text Block            (depth 3)
â”œâ”€â”€ h2: Second Chapter            (depth 1)
â”‚   â””â”€â”€ Table                     (depth 2)
â””â”€â”€ Image                         (depth 1)
```

### API Endpoints

- `POST /processed/{processed_document_id}/structured` - Process and structure an HTML document
- `GET /processed/{processed_document_id}/structure` - Get document structure as a hierarchical tree
- `GET /processed/{processed_document_id}/toc` - Get the table of contents (headers only) as a hierarchical tree
- `GET /processed/{processed_document_id}/search-headers?query={text}` - Search headers by content and get matching sections
- `DELETE /processed/{processed_document_id}/structure` - Delete the existing structure for a document
- `GET /nodes/{node_id}/content` - Get a specific node and its children (useful for extracting sections)